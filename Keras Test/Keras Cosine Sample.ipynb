{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/sonyisme/keras-recommendation/blob/master/keras-master/examples/movieslensDSSM.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dropout, Dense, Reshape\n",
    "from keras.layers import Merge\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user= np.zeros([1024,3883])\n",
    "items= np.zeros([1024,2,6039])\n",
    "y_train=np.zeros([1024,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = np.array([[1,0,0],[1,0,0],[0,1,0],[1,1,0]])\n",
    "#y_train = np.array([[1, 0],[1,0],[1,0],[1,0]])\n",
    "y_train = np.array([1,1,1,1])\n",
    "items = np.array(  [[1,0,1,1],[1,0,0,1],[0,1,1,1],[0,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "categorical_labels = to_categorical(y_train)\n",
    "categorical_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 Users 3 Features\n",
    "user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 Items 4 Features\n",
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 Labels\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create user model\n",
    "userModel = Sequential()\n",
    "#userModel.add(Dense(3,input_dim=3))\n",
    "userModel.add(Dense(6, input_shape=(3,)))\n",
    "userModel.add(Activation('tanh'))\n",
    "userModel.add(Dropout(0.4))\n",
    "# userModel.add(Dense(2, input_dim=3))\n",
    "userModel.add(Dense(12, input_shape=(6,)))\n",
    "userModel.add(Activation('tanh'))\n",
    "# userModel.add(Reshape((2,1)))\n",
    "userModel.add(Reshape((12,)))\n",
    "#userModel.add(Dense(12,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create item model\n",
    "itemModel = Sequential()\n",
    "#itemModel.add(Dense(3,input_dim=3))\n",
    "itemModel.add(Dense(6, input_shape=(4,)))\n",
    "itemModel.add(Activation('tanh'))\n",
    "itemModel.add(Dropout(0.4))\n",
    "# itemModel.add(Dense(2,input_dim=3))\n",
    "itemModel.add(Dense(12, input_shape=(6,)))\n",
    "itemModel.add(Activation('tanh'))\n",
    "# itemModel.add(Reshape((2,1)))\n",
    "itemModel.add(Reshape((12,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophia.gao/.pyenv/versions/miniconda2-latest/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Merge([userModel,itemModel], mode='cos', dot_axes=1, output_shape=(1,)))\n",
    "#print model.predict([input_a, input_b])\n",
    "model.add(Reshape((1,)))\n",
    "#y_score= model.get_output(train=False)\n",
    "#x_test=model.get_input(train=False)\n",
    "#model.add(Activation('softmax'))\n",
    "#print(model.predict([user, items]))\n",
    "#model.output(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(optimizer='rmsprop', loss='cosine_proximity', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='Adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 0s - loss: 1.1641 - acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s - loss: 5.4538 - acc: 0.2500\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s - loss: 1.1101 - acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s - loss: 6.2856 - acc: 0.0000e+00\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s - loss: 1.6260 - acc: 0.2500\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s - loss: 1.0273 - acc: 0.0000e+00\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s - loss: 5.0747 - acc: 0.0000e+00\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s - loss: 1.7765 - acc: 0.2500\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s - loss: 1.3809 - acc: 0.5000\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s - loss: 4.5820 - acc: 0.5000\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s - loss: 2.1128 - acc: 0.0000e+00\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s - loss: 5.2349 - acc: 0.2500\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s - loss: 5.0768 - acc: 0.0000e+00\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s - loss: 1.1050 - acc: 0.2500\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s - loss: 8.5392 - acc: 0.2500\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s - loss: 4.8049 - acc: 0.2500\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s - loss: 8.4169 - acc: 0.2500\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s - loss: 5.0568 - acc: 0.2500\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s - loss: 1.7809 - acc: 0.5000\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s - loss: 0.9719 - acc: 0.5000\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s - loss: 1.4003 - acc: 0.0000e+00\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s - loss: 1.0925 - acc: 0.5000\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s - loss: 4.8343 - acc: 0.2500\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s - loss: 1.3230 - acc: 0.0000e+00\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s - loss: 5.0699 - acc: 0.2500\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s - loss: 4.6519 - acc: 0.5000\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s - loss: 4.6806 - acc: 0.2500\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s - loss: 9.4183 - acc: 0.0000e+00\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s - loss: 1.7866 - acc: 0.2500\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s - loss: 1.1689 - acc: 0.2500\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s - loss: 1.0955 - acc: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophia.gao/.pyenv/versions/miniconda2-latest/envs/py36/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s - loss: 0.9391 - acc: 0.0000e+00\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s - loss: 0.8289 - acc: 0.5000\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s - loss: 2.2591 - acc: 0.0000e+00\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s - loss: 4.7061 - acc: 0.5000\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s - loss: 1.1067 - acc: 0.2500\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s - loss: 1.2795 - acc: 0.0000e+00\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s - loss: 1.8764 - acc: 0.0000e+00\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s - loss: 1.5156 - acc: 0.5000\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s - loss: 4.6957 - acc: 0.2500\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s - loss: 1.4332 - acc: 0.0000e+00\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s - loss: 0.8206 - acc: 0.5000\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s - loss: 4.9573 - acc: 0.0000e+00\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s - loss: 1.4442 - acc: 0.5000\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s - loss: 4.9080 - acc: 0.2500\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s - loss: 0.8985 - acc: 0.2500\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s - loss: 0.6921 - acc: 0.5000\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s - loss: 1.3220 - acc: 0.2500\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s - loss: 1.0732 - acc: 0.5000\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s - loss: 1.0710 - acc: 0.2500\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s - loss: 1.4220 - acc: 0.0000e+00\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s - loss: 1.1486 - acc: 0.2500\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s - loss: 1.1003 - acc: 0.2500\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s - loss: 1.2875 - acc: 0.0000e+00\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s - loss: 1.5788 - acc: 0.2500\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s - loss: 1.9189 - acc: 0.0000e+00\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s - loss: 4.6623 - acc: 0.5000\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s - loss: 1.1493 - acc: 0.5000\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s - loss: 1.3569 - acc: 0.0000e+00\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s - loss: 2.0972 - acc: 0.2500\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s - loss: 0.9038 - acc: 0.2500\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s - loss: 0.9397 - acc: 0.5000\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s - loss: 4.7883 - acc: 0.2500\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s - loss: 0.7586 - acc: 0.5000\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s - loss: 1.3578 - acc: 0.5000\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s - loss: 0.8634 - acc: 0.5000\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s - loss: 1.0333 - acc: 0.5000\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s - loss: 1.0565 - acc: 0.0000e+00\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s - loss: 1.3534 - acc: 0.0000e+00\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s - loss: 1.0103 - acc: 0.2500\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s - loss: 1.0613 - acc: 0.2500\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s - loss: 0.9389 - acc: 0.2500\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s - loss: 1.2056 - acc: 0.2500\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s - loss: 1.1713 - acc: 0.5000\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s - loss: 1.2589 - acc: 0.2500\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s - loss: 1.3405 - acc: 0.5000\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s - loss: 1.1384 - acc: 0.5000\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s - loss: 1.9838 - acc: 0.0000e+00\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s - loss: 0.8193 - acc: 0.2500\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s - loss: 8.7274 - acc: 0.0000e+00\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s - loss: 1.4412 - acc: 0.5000\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s - loss: 1.8440 - acc: 0.0000e+00\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s - loss: 1.8662 - acc: 0.0000e+00\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s - loss: 1.8196 - acc: 0.0000e+00\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s - loss: 1.3269 - acc: 0.0000e+00\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s - loss: 4.8079 - acc: 0.2500\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s - loss: 4.9760 - acc: 0.5000\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s - loss: 0.8062 - acc: 0.2500\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s - loss: 0.7836 - acc: 0.5000\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s - loss: 1.0480 - acc: 0.5000\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s - loss: 0.7697 - acc: 0.7500\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s - loss: 1.0150 - acc: 0.2500\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s - loss: 1.2107 - acc: 0.0000e+00\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s - loss: 5.3116 - acc: 0.0000e+00\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s - loss: 4.6552 - acc: 0.2500\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s - loss: 2.2329 - acc: 0.0000e+00\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s - loss: 0.9596 - acc: 0.5000\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s - loss: 1.1014 - acc: 0.0000e+00\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s - loss: 0.8770 - acc: 0.2500\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s - loss: 4.6485 - acc: 0.2500\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s - loss: 1.6456 - acc: 0.0000e+00\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s - loss: 1.7481 - acc: 0.2500\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s - loss: 1.0708 - acc: 0.2500\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s - loss: 1.1470 - acc: 0.2500\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s - loss: 4.8968 - acc: 0.2500\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s - loss: 0.8492 - acc: 0.2500\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s - loss: 1.0717 - acc: 0.5000\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s - loss: 1.0504 - acc: 0.2500\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s - loss: 1.2892 - acc: 0.7500\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s - loss: 1.0258 - acc: 0.0000e+00\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s - loss: 4.8193 - acc: 0.2500\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s - loss: 1.5626 - acc: 0.2500\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s - loss: 1.9726 - acc: 0.2500\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s - loss: 1.8876 - acc: 0.2500\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s - loss: 0.9913 - acc: 0.5000\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s - loss: 0.9589 - acc: 0.2500\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s - loss: 4.9504 - acc: 0.2500\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s - loss: 5.3820 - acc: 0.0000e+00\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s - loss: 1.2857 - acc: 0.0000e+00\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s - loss: 1.1596 - acc: 0.2500\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s - loss: 0.7842 - acc: 0.7500\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s - loss: 1.2051 - acc: 0.2500\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s - loss: 0.6599 - acc: 0.7500\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s - loss: 1.3743 - acc: 0.5000\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s - loss: 1.0923 - acc: 0.0000e+00\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s - loss: 4.9039 - acc: 0.2500\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s - loss: 4.6120 - acc: 0.5000\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s - loss: 1.0254 - acc: 0.2500\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s - loss: 0.7985 - acc: 0.2500\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s - loss: 1.0478 - acc: 0.2500\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s - loss: 4.7106 - acc: 0.5000\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s - loss: 1.3214 - acc: 0.2500\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s - loss: 2.2163 - acc: 0.0000e+00\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s - loss: 5.8728 - acc: 0.2500\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s - loss: 1.2324 - acc: 0.2500\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s - loss: 1.1870 - acc: 0.2500\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s - loss: 1.5095 - acc: 0.2500\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s - loss: 4.3831 - acc: 0.7500\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s - loss: 0.8873 - acc: 0.5000\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s - loss: 1.6041 - acc: 0.2500\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s - loss: 1.4670 - acc: 0.0000e+00\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s - loss: 1.4425 - acc: 0.0000e+00\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s - loss: 1.4051 - acc: 0.5000\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s - loss: 4.6835 - acc: 0.2500\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s - loss: 0.7395 - acc: 0.5000\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s - loss: 4.4071 - acc: 0.5000\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s - loss: 0.6865 - acc: 0.7500\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s - loss: 4.7240 - acc: 0.2500\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s - loss: 1.1726 - acc: 0.5000\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s - loss: 1.0701 - acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1826126b70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit([user, items],y_train, nb_epoch = 150, batch_size=10) # epochs=150 in keras 2+\n",
    "\n",
    "#model.fit([user, items],categorical_labels, nb_epoch = 150, batch_size=10) # epochs=150 in keras 2+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s\n",
      "\n",
      "acc: 50.00%\n",
      "[array([[ 0.70315003],\n",
      "       [ 0.68608069],\n",
      "       [ 0.60361624],\n",
      "       [ 0.60361624]], dtype=float32), array([[ 0.70315003],\n",
      "       [ 0.68608069],\n",
      "       [ 0.60361624],\n",
      "       [ 0.60361624]], dtype=float32), array([[ 0.43012592],\n",
      "       [ 0.54070216],\n",
      "       [ 0.30999482],\n",
      "       [ 0.30999482]], dtype=float32), array([[ 0.56645173],\n",
      "       [ 0.65550613],\n",
      "       [ 0.42587402],\n",
      "       [ 0.42587402]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate([user,items], y_train)\n",
    "result = list()\n",
    "l = len(user)\n",
    "for u in user:\n",
    "    temp = np.array([u] * l)\n",
    "    result.append(model.predict([temp,items], batch_size=32, verbose=0))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predictions = model.predict([user,items])\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(predictions).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## COSINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(input_a)? (<ipython-input-18-bbaf10674948>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-bbaf10674948>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print input_a\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(input_a)?\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, merge\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "input_a = np.reshape([1, 2, 3], (1, 1, 3))\n",
    "print input_a\n",
    "input_b = np.reshape([4, 5, 6], (1, 1, 3))\n",
    "print input_b\n",
    "\n",
    "a = Input(shape=(1, 3))\n",
    "print a\n",
    "b = Input(shape=(1, 3))\n",
    "print b\n",
    "\n",
    "concat = merge([a, b], mode='concat', concat_axis=-1)\n",
    "dot = merge([a, b], mode='dot', dot_axes=2)\n",
    "cos = merge([a, b], mode='cos', dot_axes=2)\n",
    "\n",
    "model_concat = Model(input=[a, b], output=concat)\n",
    "model_dot = Model(input=[a, b], output=dot)\n",
    "model_cos = Model(input=[a, b], output=cos)\n",
    "\n",
    "print(model_concat.predict([input_a, input_b]))\n",
    "print(model_dot.predict([input_a, input_b]))\n",
    "print(model_cos.predict([input_a, input_b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "4 train sequences\n",
      "user_train shape: (4, 3)\n",
      "Item shape: (4, 3)\n",
      "done model construction\n",
      "done complie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophia.gao/.pyenv/versions/miniconda2-latest/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:64: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Users/sophia.gao/.pyenv/versions/miniconda2-latest/envs/py36/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_9 to have shape (None, 1) but got array with shape (4, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c7b9d86b3461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#scoring= theano.function(x_test,y_score,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m#            allow_input_downcast=True, mode=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mItems\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m#history = model.train_on_batch([user ,Items] ,y_train,accuracy=True)# nb_epoch=10, batch_size=1024, verbose=2, show_accuracy=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda2-latest/envs/py36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda2-latest/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda2-latest/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1383\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1384\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda2-latest/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_9 to have shape (None, 1) but got array with shape (4, 2)"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# theano\n",
    "\n",
    "def inspect_inputs(i, node, fn):\n",
    "    print (i)\n",
    "    print (node)\n",
    "    print (\"input(s) value(s):\")\n",
    "    print ([input[0] for input in fn.inputs])\n",
    "\n",
    "def inspect_outputs(i, node, fn):\n",
    "    print( \"output(s) value(s):\", [output[0] for output in fn.outputs])\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    #user=   np.array([[1,0],[1,0],[0,1]])\n",
    "    #y_train=np.array([[1,0],[1,0],[1,0]])\t\n",
    "    #Items=np.array(  [ [[1,0],[0,1]] , [[.5,0],[0,1]],[[-1,1],[1,0]] ])\n",
    "    user=   np.array([[1,1,1],[1,3,1],[0,1,0],[0,2,-1]])\n",
    "    y_train=np.array([[1,0],[1,0],[1,0],[1,0]])\t\n",
    "    Items=np.array([[1,2,0],[0,2,0] , [2,2,1],[2,0,2]])#],[[0,1,2],[1,0,0]],[[1,3,3],[1,3,-1]] ])\n",
    "\t#user=   np.array([[0,1]])\n",
    "\t#y_train=np.array([[1,0]])\t\n",
    "\t#Items=np.array(  [[[-1,1],[1,0]]])\n",
    "\t# The inputs come as vectors, we reshape them to monochrome 2D images,\n",
    "    # according to the shape convention: (examples, channels, rows, columns)\n",
    "    user.reshape(-1,3);\n",
    "    # We just return all the arrays in order, as expected in main().\n",
    "    # (It doesn't matter how we do this as long as we can read them again.)\n",
    "    return (user ,Items, y_train)\n",
    "\n",
    "\n",
    "print(\"Loading data...\")\n",
    "user ,Items, y_train = load_dataset()\n",
    "print(len(user), 'train sequences')\n",
    "\n",
    "print('user_train shape:', user.shape)\n",
    "print('Item shape:', Items.shape)\n",
    "userModel = Sequential()\n",
    "userModel.add(Dense(3, input_shape = (3,)))\n",
    "userModel.add(Activation('tanh'))\n",
    "userModel.add(Dropout(0.1))\n",
    "userModel.add(Dense(2, input_shape = (3,)))\n",
    "userModel.add(Activation('tanh'))\n",
    "\n",
    "itemModel = Sequential()\n",
    "itemModel.add(Dense(3, input_shape = (3,)))\n",
    "itemModel.add(Activation('tanh'))\n",
    "itemModel.add(Dropout(0.1))\n",
    "itemModel.add(Dense(2, input_shape = (3,)))\n",
    "itemModel.add(Activation('tanh'))\n",
    "##itemModel.add(Reshape(4))\n",
    "##itemModel.add(Dense(4, 2))\n",
    "model=Sequential()\n",
    "model.add(Merge([userModel,itemModel], mode='mul', dot_axes=1, output_shape=(1,)))\n",
    "model.add(Dense(1, input_shape = (2,)))\n",
    "##model.add(Activation('normalization'))\n",
    "model.add(Reshape((1,)))\n",
    "#y_score= model.output(train=False)\n",
    "#x_test=model.input(train=False)\n",
    "model.add(Activation('softmax'))\n",
    "##model.add(Merge([userModel, itemModel], mode='sum'))\n",
    "\n",
    "\n",
    "print('done model construction')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adadelta')\n",
    "print('done complie')\n",
    "#scoring= theano.function(x_test,y_score,\n",
    "#            allow_input_downcast=True, mode=None)\n",
    "history = model.fit([user ,Items] ,y_train, nb_epoch=5, batch_size=1024, verbose=2)\n",
    "\n",
    "#history = model.train_on_batch([user ,Items] ,y_train,accuracy=True)# nb_epoch=10, batch_size=1024, verbose=2, show_accuracy=True)\n",
    "print('done training')\n",
    "#user_test ,Items_test, y_test = load_dataset(r\"C:\\Users\\t-alie\\Downloads\\movieLens_1M\\movielens.userstest100k.centered\",r\"C:\\Users\\t-alie\\Downloads\\movieLens_1M\\movielens.itemstest100k\",r\"C:\\Users\\t-alie\\Downloads\\movieLens_1M\\movielens.itemstest100k.fakeneg\",50781)\n",
    "y_p=model.predict([user,Items])\n",
    "y_pp=model.custom_predict([user,Items],scoring)\n",
    "print('done score compile')\n",
    "\n",
    "pfile=open(r\"testdata\\movieLens_1M\\yp\",\"w\")\n",
    "for y in y_p:\n",
    "    pfile.write(\"%s\\n\" %y )\n",
    "\n",
    "for y in y_pp:\n",
    "    pfile.write(\"%s\\n\" %y )\n",
    "\n",
    "\n",
    "pfile.close()\n",
    "\n",
    "print('done prediction')\n",
    "#model.save_weights(r'f:\\1b.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
